{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEB SCRAPING "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#working with images\n",
    "! pip install opencv-python\n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "from skimage import io\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "#--Web scraping packages\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import itertools\n",
    "from urllib.request import Request, urlopen\n",
    "import urllib.request\n",
    "\n",
    "#Pandas/numpy for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.request import urlopen\n",
    "\n",
    "#barrita de progreso\n",
    "from tqdm.notebook import tqdm\n",
    "from time import sleep \n",
    "\n",
    "#Visualize data\n",
    "%pylab inline\n",
    "plt.style.use('seaborn-talk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions that gets a dictionary (setas_dct) from a webpage with the url \"https://www.fungipedia.org....\"\"\n",
    "#with all mushrooms with their name and url.\n",
    "\n",
    "def get_mushrooms_info():\n",
    "    mushroom_dct = {}\n",
    "\n",
    "    for idx in tqdm(range(0, 541, 20)):\n",
    "        url = f\"https://www.fungipedia.org/hongos.html?start={idx}\"\n",
    "        req = Request(\n",
    "            url,\n",
    "            headers={\"User-Agent\": \"Safari/537.36\"},\n",
    "        )\n",
    "\n",
    "        html = urlopen(req)\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "        mushrooms = soup.find_all(class_=\"gris\")\n",
    "        for m in mushrooms:\n",
    "            mushroom_dct[m.get(\"title\")] = m.get(\"href\")\n",
    "\n",
    "    return mushroom_dct\n",
    "\n",
    "#setas_dct is a dictionary with Info about all mushrooms in the webpage (542)\n",
    "#setas_dct_short is a dictionary with Info about the first 10 mushrooms in the webpage (10)\n",
    "\n",
    "setas_dct = get_mushrooms_info()\n",
    "print(f\"Numero de setas encontradas: {len(setas_dct)}\")\n",
    "\n",
    "N = 10\n",
    "print(f\"Info de las primeras {N} setas\")\n",
    "\n",
    "setas_dct_short = dict(itertools.islice(setas_dct.items(), 10))\n",
    "for name, link in setas_dct_short.items():\n",
    "    print(f\"Seta {name} en {link}\")\n",
    "    \n",
    "#separate between names an urls mushrooms    \n",
    "setas_nombres,setas_urls=list(setas_dct.keys()), list(setas_dct.values())\n",
    "\n",
    "setas_nombres_10,setas_urls_10 = list(setas_dct_short.keys()), list(setas_dct_short.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to download the images from an url and save in a folder.\n",
    "\n",
    "def downloader(url,folder):\n",
    "    \n",
    "    os.chdir(os.path.join(os.getcwd(),'/home/dsc/FP_Mushrooms/Mushrooms_Classification/'))\n",
    "\n",
    "    try:\n",
    "        os.mkdir(os.path.join(os.getcwd(),folder))\n",
    "    except:\n",
    "        print('already created')\n",
    "\n",
    "    os.chdir(os.path.join(os.getcwd(),'/home/dsc/FP_Mushrooms/Mushrooms_Classification/'+folder))\n",
    "    \n",
    "    response = requests.get(url)\n",
    "\n",
    "    soup = BeautifulSoup(response.content,'html.parser')\n",
    "\n",
    "    images = soup.find_all(\"img\")\n",
    "    \n",
    "    number = 0\n",
    "\n",
    "    for image in images[1::]:\n",
    "    \n",
    "        image_src = image['src']\n",
    "    \n",
    "        urllib.request.urlretrieve(image_src, str(number) + \".jpg\")\n",
    "    \n",
    "        number += 1\n",
    "        \n",
    "for seta in tqdm(setas_nombres_10):\n",
    "    \n",
    "    url = 'https://www.google.com/search?q='+seta+'&tbm=isch&hl=es&sa=X&ved=2ahUKEwjw_M7z2NfuAhUMpRoKHbPQAokQgowBegQIARAX&biw=1905&bih=852'\n",
    "    \n",
    "    downloader(url,seta)\n",
    "    \n",
    "#volvemos a nuestro directorio    \n",
    "os.chdir(os.path.join(os.getcwd(),'/home/dsc/FP_Mushrooms/Mushrooms_Classification/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora nos vamos a google colab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
