{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEB SCRAPING "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#working with images\n",
    "! pip install opencv-python\n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "from skimage import io\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "#--Web scraping packages\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import itertools\n",
    "from urllib.request import Request, urlopen\n",
    "import urllib.request\n",
    "\n",
    "#Pandas/numpy for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.request import urlopen\n",
    "\n",
    "#barrita de progreso\n",
    "from tqdm.notebook import tqdm\n",
    "from time import sleep \n",
    "\n",
    "#Visualize data\n",
    "%pylab inline\n",
    "plt.style.use('seaborn-talk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping the species of mushrooms we want, only the names at the moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to have 542 species of muchrooms over the world\n",
    "\n",
    "def get_all_mushrooms():\n",
    "    mushroom_dct = {}\n",
    "\n",
    "    for idx in tqdm(range(0, 541, 20)):\n",
    "        url = f\"https://www.fungipedia.org/hongos.html?start={idx}\"\n",
    "        req = Request(\n",
    "            url,\n",
    "            headers={\"User-Agent\": \"Mozilla&5.0\"},\n",
    "        )\n",
    "\n",
    "        html = urlopen(req)\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        \n",
    "        mushrooms = soup.find_all(class_=\"gris\")\n",
    "        for m in mushrooms:\n",
    "            mushroom_dct[m.get(\"title\")] = m.get(\"href\")\n",
    "            \n",
    "    return mushroom_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions that gets a dictionary (setas_dct) from a webpage with the url \"https://www.fungipedia.org....\"\"\n",
    "#with all mushrooms with their name and url., after doing this, we decide to use also Guadalajara Mushrooms, but\n",
    "#this is to scrape the names of more than 500 mushrooms from fungipedia or 49 mushrooms exclusively from \n",
    "#Guadalajara.This is the find mushrooms cell.\n",
    "\n",
    "print(\"Choose between All the regions or only Guadalajara Mushrooms\")\n",
    "\n",
    "def get_mushrooms_region(Region=input()):\n",
    "    \n",
    "    if Region == 'All':\n",
    "        #mushrooms_dct is a dictionary with Info about all mushrooms in the webpage (542)\n",
    "        #mushrooms_dct_short is a dictionary with Info about the first 10 mushrooms in the webpage (10)\n",
    "\n",
    "        mushrooms_dct = get_all_mushrooms()\n",
    "        print(f\"Mushrooms found: {len(mushrooms_dct)}\")\n",
    "\n",
    "        N = 10\n",
    "        print(f\"Info about the first {N} mushrooms\")\n",
    "\n",
    "        mushrooms_dct_short = dict(itertools.islice(mushrooms_dct.items(), 10))\n",
    "        for name, link in mushrooms_dct_short.items():\n",
    "            print(f\"Mushroom {name} in {link}\")\n",
    "    \n",
    "        #separate between names an urls mushrooms    \n",
    "        mushrooms_names,mushrooms_urls=list(mushrooms_dct.keys()), list(mushrooms_dct.values())\n",
    "\n",
    "        mushrooms_names_10,mushrooms_urls_10 = list(mushrooms_dct_short.keys()), list(mushrooms_dct_short.values())\n",
    "        \n",
    "        return mushrooms_names\n",
    "        \n",
    "    elif Region == 'Guadalajara':\n",
    "        #I put the 50 most commons classes of Guadalajara\n",
    "            \n",
    "        mushrooms_names = ['Agaricus arvensis','Agaricus bitorquis','Agaricus campestris','Agaricus sylvaticus','Amanita caesarea','Amanita citrina',\n",
    "                     'Amanita curtipes','Amanita muscaria','Amanita pantherina','Amanita phalloides','Boletus aereus','Boletus aestivalis','Boletus edulis',\n",
    "                     'Boletus erythropus','Boletus luridus','Boletus pinophilus','Boletus satanas','Cantharellus cibarius','Clitocybe gibba','Clitocybe odora',\n",
    "                     'Cratarellus cornucopioide','Cratarellus lutescens','Ganoderma lucidum','Lactarius controversus','Lactarius controversus','Lactarius deliciosus',\n",
    "                     'Lactarius rufus','Lactarius sanguifluus','Lepista nuda','Macrolepiota mastoidea','Macrolepiota procera','Marasmius oreades','Morchella elata',\n",
    "                     'Morchella esculenta','Morchella vulgaris','Pleurotus eryngii','Pleurotus ostreatus','Russula chloroides','Russula cyanoxantha','Russula vesca',\n",
    "                     'Sparasis crispa','Suillus luteus','Terfecia leptoderma','Tricholoma columbetta','Tricholoma equestre','Tricholoma portentosum','Tuber aestivum',\n",
    "                     'Tuber brumale','Tuber melanosporum']\n",
    "            \n",
    "        print('You choose Guadalajara Mushrooms')\n",
    "        \n",
    "        return mushrooms_names\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        print('The region must be All or Guadalajara, please, try again:')\n",
    "        return get_mushrooms_region(Region=input())\n",
    "        \n",
    "        \n",
    "Mushrooms_names = get_mushrooms_region()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we save in a csv the list of mushrooms names to not always \n",
    "\n",
    "pd.Series(Mushrooms_names).to_csv('mushrooms_names.csv',sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We read the csv with the names. We do this so as not to always run the find mushrooms cell.\n",
    "\n",
    "Mushrooms_names=pd.read_csv('mushrooms_names.csv',sep='|')\n",
    "Mushrooms_names=list(Mushrooms_names['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to download the images from an url and save in a folder, if we choose All regions, we\n",
    "#are going to download 20 images for each mushroom, if we choose Guadalajara, we are going to download 300\n",
    "# for each mushroom: \n",
    "\n",
    "print(\"Where do you want to save the photos?, example: /home/dsc/FP_Mushrooms/Mushrooms_Classification_Guadalajara\")\n",
    "\n",
    "path_output = input()\n",
    "\n",
    "if path_output == 'Default':\n",
    "    path_output = os.getcwd()+'/'\n",
    "else:\n",
    "    path_output = path_output\n",
    "\n",
    "def downloader(url,folder,scroll_until):\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        os.chdir(os.path.join(os.getcwd(),path_output))\n",
    "\n",
    "        try:\n",
    "            os.mkdir(os.path.join(os.getcwd(),folder))\n",
    "        except:\n",
    "            print(mushroom+' folder already created')\n",
    "\n",
    "        os.chdir(os.path.join(os.getcwd(),path_output+folder))\n",
    "\n",
    "        num_res = scroll_until\n",
    "        \n",
    "        ## scrape 20 images from 20 images of google images until the num_res we consider necessary\n",
    "\n",
    "        for start in range(0, num_res, 20):\n",
    "\n",
    "            response = requests.get(url.format(start))\n",
    "\n",
    "            soup = BeautifulSoup(response.content,'html.parser')\n",
    "\n",
    "            images = soup.find_all(\"img\")\n",
    "\n",
    "            number = 0 + start\n",
    "            \n",
    "            for image in images[1::]:\n",
    "\n",
    "                image_src = image['src']\n",
    "\n",
    "                urllib.request.urlretrieve(image_src, str(number) + \".jpg\")\n",
    "\n",
    "                number += 1\n",
    "    except:\n",
    "        print('The Mushroom '+folder+' has had some errors in the download , to revise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"How many images per mushroom do you want?\")\n",
    "\n",
    "scroll_until=int(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mushroom in tqdm(Mushrooms_names):\n",
    "    \n",
    "    url = 'https://www.google.com/search?q='+mushroom+'&tbm=isch&hl=es&sa=X&ved=2ahUKEwjw_M7z2NfuAhUMpRoKHbPQAokQgowBegQIARAX&biw=1905&bih=852&start={}'\n",
    "    \n",
    "    downloader(url,mushroom,scroll_until)\n",
    "    \n",
    "#volvemos a nuestro directorio  \n",
    "os.chdir(os.path.join(os.getcwd(),path_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we pass the download images to google colab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
